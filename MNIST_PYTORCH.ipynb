{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE8Brv_xw-eB"
      },
      "outputs": [],
      "source": [
        "#Import dependencies\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch import nn, save,load\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17M8X1d0xwOG",
        "outputId": "a01dd240-af5c-4b02-b8f1-d9e1d6430b5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "train_data= datasets.MNIST(root=\"/content/gdrive/MyDrive/assignment3_DS\",download=False,train=True,transform=ToTensor())\n",
        "dataset_32=DataLoader(train_data,32) #creat batchs of 32 images"
      ],
      "metadata": {
        "id": "UGbxaiJxxYlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_1=DataLoader(train_data,1)"
      ],
      "metadata": {
        "id": "vC522Zb3SiAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploring the dataset, size, shape..Â²\n",
        "for i,d in enumerate(dataset_1):\n",
        "  print(len(d[0][0][0][0]))\n",
        "  if i==0:\n",
        "    break"
      ],
      "metadata": {
        "id": "G6ezKZWGAd_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Design\n",
        "class ImageClassifierNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model=nn.Sequential(\n",
        "        nn.Conv2d(1,32,(3,3)),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32,64,(3,3)),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64,64,(3,3)),\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(64*(28-6)*(28-6),10)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.model(x)\n"
      ],
      "metadata": {
        "id": "wnslMrqNybMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instiation of the model, loss, optimization\n",
        "model=ImageClassifierNN().to('cuda') # For gpu utilisation set .to('cuda) \n",
        "optimizer=Adam(model.parameters(), lr=1e-3) #(,learning rate) \n",
        "loss_fn=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "setrqTa6zwgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implimenting training function --> loop for epochs, and call the model for each dataset element\n",
        "def train(model,epochs, dataset):\n",
        "  for epoch in range(epochs):\n",
        "     total_loss=0\n",
        "     for batch in dataset:\n",
        "       X,y=batch\n",
        "       X,y=X.to('cuda'), y.to('cuda')\n",
        "       y_pred=model(X)\n",
        "       loss=loss_fn(y_pred,y)\n",
        "       #Apply bachpropagation\n",
        "       optimizer.zero_grad()\n",
        "       loss.backward()\n",
        "       optimizer.step()\n",
        "\n",
        "       total_loss += loss\n",
        "     print(f\"epoch: {epoch} , loss: {total_loss}\")\n",
        "  with open('model_state.pt','wb') as f:\n",
        "    save(model.state_dict(),f)"
      ],
      "metadata": {
        "id": "L5KfVveX0mVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, epochs=20, dataset=dataset_32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF0GVkoB5TMh",
        "outputId": "d1e23796-71af-4122-ff88-75f2fb0c5b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 , loss: 240.99476623535156\n",
            "epoch: 1 , loss: 85.49656677246094\n",
            "epoch: 2 , loss: 53.553955078125\n",
            "epoch: 3 , loss: 36.89036560058594\n",
            "epoch: 4 , loss: 26.87471580505371\n",
            "epoch: 5 , loss: 21.610427856445312\n",
            "epoch: 6 , loss: 16.82542610168457\n",
            "epoch: 7 , loss: 12.742138862609863\n",
            "epoch: 8 , loss: 12.518275260925293\n",
            "epoch: 9 , loss: 9.313807487487793\n",
            "epoch: 10 , loss: 9.777141571044922\n",
            "epoch: 11 , loss: 11.734538078308105\n",
            "epoch: 12 , loss: 6.337721824645996\n",
            "epoch: 13 , loss: 7.323587417602539\n",
            "epoch: 14 , loss: 7.6190571784973145\n",
            "epoch: 15 , loss: 7.392160415649414\n",
            "epoch: 16 , loss: 5.914453983306885\n",
            "epoch: 17 , loss: 5.182888984680176\n",
            "epoch: 18 , loss: 7.213016033172607\n",
            "epoch: 19 , loss: 6.488308429718018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DigCl99gSQa1",
        "outputId": "6e040b13-b016-4bf5-a098-0fabce3a43c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.MNIST"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data[12][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Smzlxv9pTr5W",
        "outputId": "bafa7a02-eb19-4e92-d833-dc8845f2b13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_image = train_data[0][0]\n",
        "type(random_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjBjYJrqU9s9",
        "outputId": "b490ef2b-9cda-4237-d8ab-7e66298fbca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_image = train_data[0][0]  #We must be test the model with new data but well....\n",
        "random_image=random_image.unsqueeze(0).to('cuda')\n",
        "random_image_label=train_data[0][1]\n",
        "print(random_image_label)"
      ],
      "metadata": {
        "id": "o1NLH5jKTblG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make prediction\n",
        "img_pred= torch.argmax(model(random_image))\n",
        "print(img_pred)"
      ],
      "metadata": {
        "id": "4MhTA4IaSb1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/gdrive/MyDrive/assignment3_DS/model_state.pt','wb') as f:\n",
        "    save(model.state_dict(),f)"
      ],
      "metadata": {
        "id": "X_4Z3rv2Yequ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read model:\n",
        "with open('/content/gdrive/MyDrive/assignment3_DS/model_state.pt','rb') as f:\n",
        "  model.load_state_dict(load(f))\n",
        "#If we want to test with another image\n",
        "img=Image.open('path_to_image_to_predict_its_class')\n",
        "img_tensor= ToTensor()(img).unsqueeze(0).to('cuda')#Convert image to tensor\n",
        "\n",
        "img_pred= torch.argmax(model(img_tensor))\n",
        "print(img_pred)"
      ],
      "metadata": {
        "id": "dNpnA1cUXfOq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}